---
title: "Voorbereiding Onderzoekstechnieken"
author: Jules Vervaeke
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(vcd)
library(TTR)
library(forecast)
```

```{r}
wiskunde_data <- read_csv(file ="npe-1920-wiskundige-geletterdheid.csv")
muziekwijn <- read_csv(file="MuziekWijn.csv", col_types = cols(Muziek = col_factor(levels = c("Geen", "Franse", "Italiaanse")), 
                                                               Wijn = col_factor(levels = c("Franse", "Italiaanse", "Andere"))))
passagiers2 <- read_csv(file="Passagiers2.csv") %>%
  mutate(time = parse_date(time, format = "%b-%Y"))
```
## Kwantitatieve variabelen (nominaal, ordinaal)
summary() op één rij of een volledige dataset: Een samenvatting tonen (minimum, maximum, kwartielen, mediaan en gemiddelde) 
IQR() op één rij: Interkwartielafstand berekenen
var() op één rij: variantie 
sd() op één rij: standaarddeviatie
length(): aantal waarnemingen in een rij

## Kwalitatiieve variabelen(ratio, interval)
levels(): toont alle mogelijke opties
unique(): zie hierboven
table(): toont de frequentie van alle opties


```{r}
summary(cars)
summary(cars$speed)
IQR(cars$speed)
sd(cars$speed)
variance <- sum((cars$speed - mean(cars$speed))^2)/(length(cars$speed)-1)
variance
var(cars$speed)

levels(esoph$agegp)
unique(esoph$agegp)
table(esoph$agegp)

```

## Kansen berekenen
Je kan werken met de z-score (gebaseerd op het gemiddelde en de standaardafwijking) of met de waarneming, het gemiddelde en de standaardafwijking zelf. De formules met pnorm/qnorm gelden enkel voor normale verdelingen met meer dan 30 proefpersonen

Linkerstaartkans berekent de kans dat jouw waarneming of kleiner gevonden wordt binnen de verdeling: pnorm
Rechterstaartkans berekent de kans de jouw waarneming of groter gevonden wordt binnen de verdeling: 1-pnorm

Het significantieniveau bepaalt de kans op een fout van Type I als we veronderstellen dat de nulhypothese waar is. M.a.w. dit is de kans, als H0 waar is, dat we toch een steekproef nemen met zulke extreme waarden dat het steekproefgemiddelde toch in het kritieke gebied zou liggen.


```{r}
gemiddelde <- 5
standaardafwijking <- 1.5
waarneming <- 6.5

z <- (waarneming-gemiddelde)/standaardafwijking
pnorm(z)
pnorm(waarneming, gemiddelde, standaardafwijking)

1-pnorm(z)
```

Als je een gegeven percentage krijgt, dan kan je de bijhorende waarde berekenen met qnorm
```{r}
gemiddelde <- 5
standaardafwijking <- 1.5
percentage <- 0.65

qnorm(percentage, gemiddelde, standaardafwijking)
```

Hieronder zie je het gemiddelde en de standaardafwijking van de populatie en het aantal proefpersonen binnen een nieuwe steekproef. 
Bepaal de kans dat $\overline{x}$ kleiner is dan 185, tussen 175 en 185 ligt en groter is dan 190
Let op: Vanaf hier delen we de standaarddeviatie door de vierkantswortel van het aantal waarnemingen. Dit is omdat we een normaalverdeling volgen met mean = gemiddelde en sd s/sqrt(n).

```{r}
m <- 183
s <- 36
n <- 81

pnorm(185, mean = m, sd = s / sqrt(n))
pnorm(185, mean = m, sd = s / sqrt(n)) - pnorm(175, mean = m, sd = s / sqrt(n))
1 - pnorm(190, mean = m, sd = s / sqrt(n))
```

## Betrouwbaarheidsinterval
Hoe meer waarnemingen, hoe smaller uw betrouwbaarheidsinterval. Als je minder dan 30 personen hebt, gebruik qt ipv qnorm.
Hoe zekerder je wilt zijn, hoe breder uw interval => 99% heeft een breder betrouwbaarheidsinterval dan 95%; 100% is infinity
```{r}
# Stap 1
m <- 5.2      # steekproefgemiddelde
s <- 1.5      # standaardafwijking van de populatie
n <- 100     # steekproefgrootte
alpha <- 0.05 # 1 - alpha is het zekerheidsniveau
# Stap 2
z <- qnorm(1-alpha/2) #Delen door 2 omdat je een tweezijdig interval hebt
z
# Stap 3: het betrouwbaarheidsinterval
low  <- m - z * s / sqrt(n)
high <- m + z * s / sqrt(n)
c(low, high)
```


## Z-toets
```{r}
n <- 30 
sm <- 3.483 
s <- 0.55 
a <- 0.05  
m0 <- 3.3 

# Methode 1 . Overschrijdingskans
p <- 1 - pnorm(sm, m0, s/sqrt(n)) # => 0.03419546
p

#Methode 2. Kritieke grensgebied
# Onder welke waarde kan je H0 niet verwerpen ?
g <- m0 + qnorm(1-a )*s/sqrt(n)
g
```

## T-toets (bij steekproef kleiner dan 30)
```{r}
n <- 25 
sm <- 3.483 
ss <- 0.55 
a <- 0.05 
m0 <- 3.3

# Methode 1 . Overschrijdingskans
p <- 1-pt((sm-m0)/(ss/sqrt(n)), df=n-1)
p
#OF
#t.test(NaamRij, mu = 3.3,alternative = "greater",conf.level = 1 - a, df = n-1)

#Methode 2. Kritieke grensgebied
# Onder welke waarde kan je H0 niet verwerpen ?
g <- m0 + qt(1-a ,df=n-1)*ss/sqrt(n)
g
```

## Kwalitatief-kwalitatief
Als je een kruistabel maakt, zet dan de afhankelijke variabele eerst en de onafhankelijke variabele 2de.
Bij verbanden tussen kwalitatieve variabelen gebruik je altijd de chi kwadraat test. Kramer's V duidt op de sterkte: 
V = 0 geen samenhang
V ≈ 0,1 zwakke samenhang
V ≈ 0,25 redelijk sterke samenhang
V ≈ 0,50 sterke samenhang
V ≈ 0,75 zeer sterke samenhang
V = 1 volledige samenhang

```{r}
#Kruistabel opzetten 
observed <- table(muziekwijn$Wijn, muziekwijn$Muziek)
observed
#addmargins(observed)

#Chi-squared test
model <- chisq.test(observed)
model

#Verwachte waardes (handig om de regel van Cochran te testen (alle waardes moeten minstens 1 zijn, 80% van de waardes moeten minstens 5 zijn ))
model$expected

#P-waarde
model$p.value

#Gestandaardiseerde residuen bekijken
model$stdres

#Cramer's V ()
observed_stats <- assocstats(observed)
observed_stats$cramer
```

De chi kwadraat test kan ook gebruikt worden om een goodness of fit test uit te voeren.
```{r}
types      <- c("mutant", "human", "alien", "god", "demon")
observed   <- c(   127,      75,      98,     27,     73)
expected_p <- c(   .35,     .17,     .23,    .08,    .17)

chisq_test_result <- chisq.test(observed, p = expected_p)
chisq_test_result
chisq_test_result$statistic # The value of chi squared
chisq_test_result$p.value   # The p-value
chisq_test_result$parameter # The degrees of freedom
chisq_test_result$residuals # Residuals (o - e) / sqrt(e)
chisq_test_result$stdres    # Standardised residuals (kleiner dan -2 => ondergerepresenteerd, groter dan 2 => overgerepresenteerd)
```


## Kwalitatief-kwantitaief
Gebruik maken van een t-toets om te bepalen of er een verschil is tussen de gemiddeldes van 2 steekproeven. De t-test gebruiken standaard een alpha van 0.05. In onderstaande test wordt er gekeken of de controle groep signficant lager scoort dan de interventie (1ste less than 2de). Zie omgekeerde test erna, natuurlijk zelfde resultaten.

```{r}
controle <- c(91, 87, 99, 77, 88, 91)
interventie <- c (101, 110, 103, 93, 99, 104)
t.test(controle, interventie, altnerative ="less")
t.test(interventie, controle, altnerative ="greater")
```

Een gepairde t-test gebruik je wanneer je dezelfde testpersonen een andere conditie laat uit voeren (dus altijd evenveel waarnemingen).
```{r}
gewone <- c(16, 20, 21, 22, 23, 22, 27, 25, 27, 28)
additieven <- c (19, 22, 24, 24, 25, 25, 26, 26, 28, 32)
t.test(additieven, gewone, altnerative ="greater", paired=TRUE)
```

Cohen's D: Formule
0,01 Zeer klein
0,20 Klein
0,50 Middelmatig
0,80 Groot
1,20 Zeer groot
2,00 Reusachtig

```{r}
# Pooled standard deviation for two samples x and y
pooled_sd <- function(x, y) {
  sd_x <- sd(x, na.rm = TRUE)
  sd_y <- sd(y, na.rm = TRUE)
  n_x <- length(x)
  n_y <- length(y)
  
  sqrt( ((n_x - 1) * sd_x^2 + (n_y - 1) * sd_y^2)
        / (n_x + n_y - 2))
}
# Effect size, Cohen's d
cohens_d <- function(x, y) {
  (mean(y, na.rm = TRUE) - mean(x, na.rm = TRUE)) / pooled_sd(x, y)
}

#Cohen's D oproepen
cohens_d(controle, interventie)
```

## Kwantitatief-kwantitatief
Gebruik maken van een regressierechte, correlatie en determinatiecoëfficient


```{r}
resultaten <- tibble(
  test = c(10, 12, 8, 13, 9, 10, 7, 14, 11, 6),
  examen = c(11, 14, 9, 13, 9, 9, 8, 14, 10, 6)
)

#In de functie lm zet je altijd eerst uw afhankelijke variabele en dan uw onafhankelijke. Je krijgt uw snijpunt met de y-as en uw rico
examen_test_lm <- lm(resultaten$examen ~ resultaten$test)
examen_test_lm

#Correlatie berekenen: Sterkte van het verband berekenen (tussen -1 en 1)
correlatie <- cor(resultaten$test, resultaten$examen)
correlatie

#Determinatiecoëfficient berekenen: De hoeveelheid variantie in de resultaten die met dit verband verklaart kan worden
determinatiecoëfficient <- correlatie^2
determinatiecoëfficient
```

## Tijdreeksen
```{r}
weekly_demand <- c(
  4, 16, 12, 25, 13, 12, 4,  8, 9, 14,
  3, 14, 14, 20,  7,  9, 6, 11, 3, 11,
  8,  7,  2,  8,  8, 10, 7, 16, 9,  4
)
demand_ts <- ts(weekly_demand)
plot.ts(demand_ts, type = 'b', pch = 20,
        xlab = "Time (weeks)",
        ylab = "Weekly demand")


passagiers <- ts(start = c(1949, 1),
                 end = c(1960, 12),
                 frequency = 12,
                 data = passagiers2$AirPassengers)
passagiers
plot.ts(passagiers)
```

Lineaire regressie (Weekly demand hier eens bijgezet omdat er daar gebruik gemaakt wordt van time OF 1:length)
```{r}
lm(weekly_demand ~ time(weekly_demand))
week <- 1:length(weekly_demand)
lm(weekly_demand ~ week)

lm(passagiers ~ time(passagiers))
```

Exponential Moving Average (alpha dicht bij 0 => minder snel vergeten, alpha dicht 1 => snel vergeten)
Dit zorgt voor dezelfde voorspelling van 1 punt (meestal niet handig dus)
```{r}
pass_ema1 <- HoltWinters(passagiers, alpha = 0.2, beta = FALSE, gamma = FALSE)
plot(pass_ema1, main = "Exponential Moving Average")
pass_ema1_fc <- forecast(pass_ema1, h=10)
pass_ema1_fc
plot(pass_ema1_fc, main = "Forecast with Exponential Moving Average")
```

Double Exponential Moving Average (Voor data met een lange trend, dalend of stijgend)
Dit zorgt voor voorspellingen met een stijgende/dalende aard
```{r}
pass_ema2 <- HoltWinters(passagiers, alpha = 0.8, beta = 0.2, gamma = FALSE)
plot(pass_ema2, main = "Double Exponential Moving Average")
pass_ema2_fc <- forecast(pass_ema2, h = 10)
pass_ema2_fc
plot(pass_ema2_fc)
```

Triple Exponential Moving Average (voor data met een algemene trend maar met een terugkerend patroon/schommeling)
```{r}
pass_ema3 <- HoltWinters(passagiers)
plot(pass_ema3, main = "Triple Exponential Moving Average")
pass_ema3_fc <- forecast(pass_ema3, h = 24)
pass_ema3_fc
plot(pass_ema3_fc)
```